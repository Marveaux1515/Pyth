{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,numpy as np,re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from time import time\n",
    "from tensorflow.keras import models\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from model import predict_img\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory/file 'Image_data\\Train' already created\n",
      "Directory/file 'Image_data\\Test' already created\n",
      "Directory/file 'Image_data\\Complete_images' already created\n"
     ]
    }
   ],
   "source": [
    "#creating train and test directories\n",
    "try:\n",
    "    os.mkdir(\"Image_data\")\n",
    "except FileExistsError:\n",
    "    for dir_ in [\"Image_data\\\\Train\",\"Image_data\\\\Test\",\"Image_data\\\\Complete_images\"]:\n",
    "        try:\n",
    "            os.mkdir(dir_)\n",
    "        except FileExistsError:\n",
    "            print(f\"Directory/file '{dir_}' already created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file/directory Image_data\\Train\\2_digits already exists\n",
      "The file/directory Image_data\\Train\\1_digit already exists\n",
      "The file/directory Image_data\\Test\\2_digits already exists\n",
      "The file/directory Image_data\\Test\\1_digit already exists\n",
      "The file/directory Image_data\\Valid\\2_digits already exists\n",
      "The file/directory Image_data\\Valid\\1_digit already exists\n"
     ]
    }
   ],
   "source": [
    "#creating the training,validation and test data sets\n",
    "Train_1=\"Image_data\\\\Train\\\\2_digits\"\n",
    "Train_2=\"Image_data\\\\Train\\\\1_digit\"\n",
    "Test_1=\"Image_data\\\\Test\\\\2_digits\"\n",
    "Test_2=\"Image_data\\\\Test\\\\1_digit\"\n",
    "Valid_1=\"Image_data\\\\Valid\\\\2_digits\"\n",
    "Valid_2=\"Image_data\\\\Valid\\\\1_digit\"\n",
    "Train=[Train_1,Train_2]\n",
    "Test=[Test_1,Test_2]\n",
    "Valid=[Valid_1,Valid_2]\n",
    "for path in [Train,Test,Valid]:\n",
    "    for label_path in path:\n",
    "        try:\n",
    "            os.mkdir(label_path)\n",
    "        except FileExistsError:\n",
    "            print(f\"The file/directory {label_path} already exists\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy =  0.9071131290200529\n"
     ]
    }
   ],
   "source": [
    "def rename_images()->None:\n",
    "    model_paths=[\".model_wts(10-30).hdf5\",\".model_wts(1-9).hdf5\"]\n",
    "    mode=[models.load_model(path_) for path_ in model_paths]\n",
    "    downloaded_img_path=\"C:\\\\Users\\\\DELL\\\\Pictures\\\\Sidegig\\\\Sidegigcaptcha7\"\n",
    "    new_images=os.listdir(downloaded_img_path)\n",
    "    for imge in new_images:\n",
    "        if os.path.isdir(downloaded_img_path+f\"\\\\{imge}\"):\n",
    "            continue\n",
    "        height, width, channels=36,60,4\n",
    "        img_arr=cv2.imread(downloaded_img_path+f\"\\\\{imge}\")\n",
    "        img_arr=cv2.cvtColor(img_arr,cv2.COLOR_BGR2RGBA)\n",
    "        img_full_resized=cv2.resize(img_arr,(700,500))\n",
    "        try:\n",
    "            img_arr=img_arr.reshape(height, width*2,channels)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        img_arr_1=img_arr[:,:img_arr.shape[1]//2,:]\n",
    "        img_arr_2=img_arr[:,img_arr.shape[1]//2:,:]\n",
    "        prop_names=[]\n",
    "        for i,img_array in enumerate([img_arr_1,img_arr_2]):\n",
    "            img_array=img_array.reshape(1,height, width,channels)\n",
    "            img_array=tf.constant(img_array)\n",
    "            classes=os.listdir(Train[i])\n",
    "            cls_map={idx:int(j) for idx, j in enumerate(classes)}\n",
    "            prop_name=predict_img(img_array/255,model=mode[i],mapp=cls_map)\n",
    "            \n",
    "            prop_names.append(int(prop_name))\n",
    "        cv2.putText(img_full_resized,f\"{prop_names[0]}_{prop_names[1]}\",(150,100),cv2.FONT_HERSHEY_COMPLEX,2,(0,0,255),2)\n",
    "        cv2.imshow(\"Image\",img_full_resized)\n",
    "        cv2.waitKey(300)\n",
    "        corr=input(\"are the values displayed in red on the image the same as the numbers in the image?\" \n",
    "            \"\\nif yes press enter,please make sure the number displayed is correct before hitting enter,\\nelse write the correct digit in the form 'digit_digit' e.g 20_8, and hit enter \\n\")\n",
    "        cv2.destroyAllWindows()\n",
    "        if corr==\"\":\n",
    "            if os.path.exists(f\"{downloaded_img_path}\\\\train_\\\\\")==False:\n",
    "                \n",
    "                os.mkdir(f\"{downloaded_img_path}\\\\train_\\\\\")\n",
    "            os.rename(downloaded_img_path+f\"\\\\{imge}\",\n",
    "            f\"{downloaded_img_path}\\\\train_\\\\{prop_names[0]}_{prop_names[1]} {imge}\")\n",
    "        else:\n",
    "            match=re.search(\"^\\d{2}_\\d$\",corr)\n",
    "            while not match:\n",
    "                cv2.putText(img_full_resized,f\"{prop_names[0]}_{prop_names[1]}\",(150,100),cv2.FONT_HERSHEY_COMPLEX,2,(0,0,255),2)\n",
    "                cv2.imshow(\"Image\",img_full_resized)\n",
    "                cv2.waitKey(300)\n",
    "                corr=input(\"Please make sure the value being written is in the form 'digits_digit'\" \n",
    "                \"e.g: 20_4, 15_9\\nalso ensure the value is the correct one\")\n",
    "                match=re.search(\"^\\d{2}_\\d$\",corr)\n",
    "                cv2.destroyAllWindows()\n",
    "            else:\n",
    "                if os.path.exists(f\"{downloaded_img_path}\\\\test_\\\\\")==False:\n",
    "                    os.mkdir(f\"{downloaded_img_path}\\\\test_\\\\\")\n",
    "                os.rename(downloaded_img_path+f\"\\\\{imge}\",\n",
    "                f\"{downloaded_img_path}\\\\test_\\\\{corr} {imge}\")\n",
    "    return\n",
    "rename_images()\n",
    "CAPTCHA_PATH=r\"C:\\Users\\DELL\\Pictures\\Sidegig\\Sidegigcaptcha7\"\n",
    "len_train=len(os.listdir(CAPTCHA_PATH+\"\\\\\"+\"train_\"))\n",
    "len_test=len(os.listdir(CAPTCHA_PATH+\"\\\\\"+\"test_\"))\n",
    "tot_len=len_test+len_train\n",
    "print(\"test_accuracy = \",len_train/tot_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to scraped captcha images,each image consists of 2 numbers,a 2-digit number and a 1-digit number e.g 20_1\n",
    "CAPTCHA_PATH=r\"C:\\Users\\DELL\\Pictures\\Sidegig\\Sidegigcaptcha7\"\n",
    "WORK_IMAGE_DIR=\"Image_data\\\\Complete_images\"\n",
    "images_folders=os.listdir(CAPTCHA_PATH)\n",
    "#move images from download/rename directory to cwd \n",
    "for dir in images_folders:\n",
    "    if os.path.isdir(CAPTCHA_PATH+\"\\\\\"+dir):\n",
    "        for images in os.listdir(CAPTCHA_PATH+\"\\\\\"+dir):\n",
    "            os.rename(f\"{CAPTCHA_PATH}\\\\{dir}\\\\{images}\",\n",
    "                    f\"{WORK_IMAGE_DIR}\\\\{dir}\\\\{images}\")\n",
    "\n",
    "#the WORK_IMAGE_DIR now contains two directories\\folders\n",
    "#train_:consists of images that were correctly classified by the last trained model\n",
    "#test_: images that were incorrectly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Train_tst_dir=os.listdir(WORK_IMAGE_DIR)\n",
    "#removing redundant information(folder name/time_stamp) and leaving only the image labels\n",
    "#Note: images have been labelled manually to include their labels in the image file_name\n",
    "#Note: after manually labelling the images initially, model was trained *see model.py* and then new images which were scraped \n",
    "#were labelled using the trained model *see rename_images()*.\n",
    "for dirs in Train_tst_dir:\n",
    "    Images=os.listdir(WORK_IMAGE_DIR+\"\\\\\"+dirs)\n",
    "    Images=[image for image in Images if not os.path.isdir(WORK_IMAGE_DIR+\"\\\\\"+dirs+\"\\\\\"+image)]\n",
    "    \n",
    "    labels=[re.sub(\"[A-Za-z\\(].+\",\"\",image_name).strip() for image_name in Images]\n",
    "    labels=[re.search(\"(\\d+)_(\\d)\",label) for label in labels]\n",
    "    labels=[label.groups() for label in labels]\n",
    "    labels\n",
    "    for i, image in enumerate(Images):\n",
    "        #split and separate the two-number images into separate folders containing single numbers\n",
    "\n",
    "        img=plt.imread(WORK_IMAGE_DIR+\"\\\\\"+dirs+\"\\\\\"+image)\n",
    "        img_2=img[:,img.shape[1]//2:,:]\n",
    "        img_1=img[:,:img.shape[1]//2,:]\n",
    "        #plt.imshow(img)\n",
    "        try:\n",
    "            os.mkdir(WORK_IMAGE_DIR+\"\\\\\"+dirs+\"\\\\2_digits\")\n",
    "            os.mkdir(WORK_IMAGE_DIR+\"\\\\\"+dirs+\"\\\\1_digit\")\n",
    "            os.mkdir(WORK_IMAGE_DIR+\"\\\\\"+dirs+\"\\\\Full_image\")\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        plt.imsave(f\"{WORK_IMAGE_DIR}\\\\{dirs}\\\\2_digits\\\\{labels[i][0]} ({i}).png\",img_1)\n",
    "        plt.imsave(f\"{WORK_IMAGE_DIR}\\\\{dirs}\\\\1_digit\\\\{labels[i][1]} ({i}).png\",img_2)\n",
    "        os.rename(WORK_IMAGE_DIR+\"\\\\\"+dirs+\"\\\\\"+image,WORK_IMAGE_DIR+\"\\\\\"+dirs+\"\\\\Full_image\\\\\"+image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fold in os.listdir(WORK_IMAGE_DIR):\n",
    "    labe_=os.listdir(f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\2_digits\")\n",
    "    labe_=[f_name for f_name in labe_ if not os.path.isdir(f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\2_digits\\\\{f_name}\")]\n",
    "    labe_2=os.listdir(f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\1_digit\")\n",
    "    labe_2=[f_name for f_name in labe_2 if not os.path.isdir(f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\1_digit\\\\{f_name}\")]\n",
    "    for file_name in labe_:\n",
    "        new_label=re.search(\"^\\d+\",file_name).group()\n",
    "        #create sub folders for each unique label \n",
    "        if os.path.exists(f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\2_digits\\\\{new_label}\")==False:\n",
    "            os.mkdir(f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\2_digits\\\\{new_label}\")\n",
    "        #move images into their corresponding label subfolder\n",
    "        os.rename(f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\2_digits\\\\{file_name}\",\n",
    "        f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\2_digits\\\\{new_label}\\\\{file_name[:-4]}{time()}.png\")\n",
    "    for file_name in labe_2:\n",
    "        new_label_2=re.search(\"^\\d\",file_name).group()\n",
    "        if os.path.exists(f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\1_digit\\\\{new_label_2}\")==False:\n",
    "            os.mkdir(f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\1_digit\\\\{new_label_2}\")\n",
    "        os.rename(f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\1_digit\\\\{file_name}\",\n",
    "        f\"{WORK_IMAGE_DIR}\\\\{fold}\\\\1_digit\\\\{new_label_2}\\\\{file_name[:-4]}{time()}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'test_': [13, 45], 'train_': [201, 499]})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "min_num_images=defaultdict(list)\n",
    "for d_set in os.listdir(WORK_IMAGE_DIR):\n",
    "\n",
    "    two_digits=f\"{WORK_IMAGE_DIR}\\\\{d_set}\\\\2_digits\"\n",
    "    one_digit=f\"{WORK_IMAGE_DIR}\\\\{d_set}\\\\1_digit\"\n",
    "    \n",
    "    for digit_type in (two_digits,one_digit):\n",
    "        labels_=os.listdir(digit_type)\n",
    "        \n",
    "        for i,cls_label in enumerate(labels_):\n",
    "            dir_images=os.listdir(digit_type+\"\\\\\"+cls_label)\n",
    "            image_length=len(dir_images)\n",
    "            if i==0:\n",
    "                min_length=image_length\n",
    "            if image_length< min_length:\n",
    "                min_length=image_length\n",
    "\n",
    "        min_num_images[d_set].append(min_length)\n",
    "print(min_num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "#percentage cut-off of images to be moved to validation and test sets\n",
    "#note the higher percentage cut-offs in dict[\"test_\"] as compared to dict[\"train\"] \n",
    "#this is to test whether the subsequent models are performing better on the test set as model retraining continues\n",
    "valid_perc={\"test_\":0.35,\"train_\":0.1}\n",
    "test_perc={\"test_\":0.2,\"train_\":0.05}\n",
    "\n",
    "\n",
    "for d_set in os.listdir(WORK_IMAGE_DIR):\n",
    "    two_digits=f\"{WORK_IMAGE_DIR}\\\\{d_set}\\\\2_digits\"\n",
    "    one_digit=f\"{WORK_IMAGE_DIR}\\\\{d_set}\\\\1_digit\"\n",
    "    for dig_typ_idx,digit_type in enumerate((two_digits,one_digit)):\n",
    "        for cls_label in os.listdir(digit_type):\n",
    "            \n",
    "            if os.path.exists(f\"{Train[dig_typ_idx]}\\\\{cls_label}\")==False:\n",
    "                os.mkdir(f\"{Train[dig_typ_idx]}\\\\{cls_label}\")\n",
    "\n",
    "            if os.path.exists(f\"{Test[dig_typ_idx]}\\\\{cls_label}\")==False:\n",
    "                os.mkdir(f\"{Test[dig_typ_idx]}\\\\{cls_label}\")\n",
    "\n",
    "            if os.path.exists(f\"{Valid[dig_typ_idx]}\\\\{cls_label}\")==False:\n",
    "                os.mkdir(f\"{Valid[dig_typ_idx]}\\\\{cls_label}\")\n",
    "\n",
    "            for image_num,image in enumerate(os.listdir(digit_type+\"\\\\\"+cls_label)):\n",
    "                #move images into training set based on the cut-offs\n",
    "                if image_num<= min_num_images[d_set][dig_typ_idx]*(1-valid_perc[d_set]):\n",
    "                    os.rename(f\"{digit_type}\\\\{cls_label}\\\\{image}\",\n",
    "                             f\"{Train[dig_typ_idx]}\\\\{cls_label}\\\\{image[:-4]}{time()}.png\")\n",
    "                #move images into Validation set based on the cut-offs\n",
    "                elif image_num<=min_num_images[d_set][dig_typ_idx]*(1-test_perc[d_set]):\n",
    "                    os.rename(f\"{digit_type}\\\\{cls_label}\\\\{image}\",\n",
    "                             f\"{Valid[dig_typ_idx]}\\\\{cls_label}\\\\{image[:-4]}{time()}.png\")\n",
    "                #move remaining images into test set \n",
    "                else:\n",
    "                    os.rename(f\"{digit_type}\\\\{cls_label}\\\\{image}\",\n",
    "                             f\"{Test[dig_typ_idx]}\\\\{cls_label}\\\\{image[:-4]}{time()}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'Train_2_digits': {402}, 'Train_1_digit': {1011}, 'Valid_2_digits': {46}, 'Valid_1_digit': {123}})\n"
     ]
    }
   ],
   "source": [
    "#for Train and Validation sets,ensure the number of images in each class label sub_folder are equal \n",
    "len_images=defaultdict(set)\n",
    "for d_set in[Train,Valid]:\n",
    "    for idx,digit_type in enumerate(d_set):\n",
    "        dataset=re.search(r\"\\\\(.*$)\",os.path.dirname(digit_type)).group(1)\n",
    "        dig_typ_name=os.path.basename(digit_type)\n",
    "        cls_labels=os.listdir(digit_type)\n",
    "        for cls_label in cls_labels:\n",
    "            dir_images=os.listdir(digit_type+\"\\\\\"+cls_label)\n",
    "            image_length=len(dir_images)        \n",
    "            len_images[dataset+\"_\"+dig_typ_name].add(image_length)\n",
    "        if len(len_images[dataset+\"_\"+dig_typ_name])>1:\n",
    "            min_length=min(len_images[dataset+\"_\"+dig_typ_name])\n",
    "            for cls_label in cls_labels:\n",
    "                dir_images=os.listdir(digit_type+\"\\\\\"+cls_label)\n",
    "                image_length=len(dir_images)\n",
    "                if image_length>min_length:\n",
    "                    excess=image_length-min_length\n",
    "                    [os.rename(digit_type+\"\\\\\"+cls_label+\"\\\\\"+dir_images[i],\n",
    "                    Test[idx]+\"\\\\\"+cls_label+\"\\\\\"+dir_images[i]) for i in range(excess)]\n",
    "\n",
    "print(len_images)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49862133fde17b1ed457465adf9e8eca8e81e31d326243e09f829dca2489f15e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('deeplng': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
